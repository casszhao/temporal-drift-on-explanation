2022-06-01 06:52:31 INFO     Running on cuda : True
2022-06-01 06:52:31 INFO     config  : 
 ----------------------
2022-06-01 06:52:31 INFO     dataset : yelp
2022-06-01 06:52:31 INFO     data_dir : /home/cass/PycharmProjects/ood_time/extract_rationales/datasets/yelp/data/
2022-06-01 06:52:31 INFO     model_dir : /home/cass/PycharmProjects/ood_time/extract_rationales/ft_kuma/yelp/
2022-06-01 06:52:31 INFO     seed : 412
2022-06-01 06:52:31 INFO     evaluate_models : False
2022-06-01 06:52:31 INFO     inherently_faithful : kuma
2022-06-01 06:52:31 INFO     use_tasc : False
2022-06-01 06:52:31 INFO     importance_metric : None
2022-06-01 06:52:31 INFO     rationale_length : 0.2
2022-06-01 06:52:31 INFO     batch_size : 8
2022-06-01 06:52:31 INFO     lr_bert : 1e-05
2022-06-01 06:52:31 INFO     lr_classifier : 0.0001
2022-06-01 06:52:31 INFO     model : bert-base-uncased
2022-06-01 06:52:31 INFO     ood_dataset_1 : yelp_ood1
2022-06-01 06:52:31 INFO     ood_dataset_2 : yelp_ood2
2022-06-01 06:52:31 INFO     epochs : 20
2022-06-01 06:52:31 INFO     model_abbreviation : kuma-bert
2022-06-01 06:52:31 INFO     evaluation_dir : None
2022-06-01 06:52:31 INFO     extracted_rationale_dir : None
2022-06-01 06:52:31 INFO     query : False
2022-06-01 06:52:31 INFO     stage_of_proj : train
2022-06-01 06:52:31 INFO     ood_rat_1 : 0.2
2022-06-01 06:52:31 INFO     ood_rat_2 : 0.2
2022-06-01 06:52:31 INFO     embed_model : glove.840B.300d
2022-06-01 06:52:31 INFO     
 ----------------------
2022-06-01 06:52:33 INFO     2022-06-01_06:52
2022-06-01 06:52:33 INFO     Finetune BERT for: yelp
2022-06-01 06:52:33 INFO     Finetune BERT for: yelp
2022-06-01 06:52:35 INFO     ***************************************
2022-06-01 06:52:35 INFO     Training on seed 412
2022-06-01 06:52:35 INFO     *saving checkpoint every 356 iterations
2022-06-01 06:52:35 INFO     +++++++++++++ epochs:  20
2022-06-01 06:53:20 INFO     *** epoch - 1 | train loss - 12.77 | dev f1 - 0.111 | dev loss - 15.63
2022-06-01 06:54:05 INFO     *** epoch - 2 | train loss - 10.73 | dev f1 - 0.111 | dev loss - 10.25
2022-06-01 06:54:50 INFO     *** epoch - 3 | train loss - 11.0 | dev f1 - 0.111 | dev loss - 11.3
2022-06-01 06:55:34 INFO     *** epoch - 4 | train loss - 11.4 | dev f1 - 0.111 | dev loss - 11.46
2022-06-01 06:56:19 INFO     *** epoch - 5 | train loss - 11.46 | dev f1 - 0.111 | dev loss - 11.47
2022-06-01 06:57:04 INFO     *** epoch - 6 | train loss - 11.47 | dev f1 - 0.111 | dev loss - 11.47
2022-06-01 06:57:48 INFO     *** epoch - 7 | train loss - 11.46 | dev f1 - 0.111 | dev loss - 11.47
2022-06-01 06:58:32 INFO     *** epoch - 8 | train loss - 11.41 | dev f1 - 0.111 | dev loss - 11.45
2022-06-01 06:59:16 INFO     *** epoch - 9 | train loss - 11.16 | dev f1 - 0.111 | dev loss - 10.97
2022-06-01 07:00:00 INFO     *** epoch - 10 | train loss - 10.78 | dev f1 - 0.111 | dev loss - 10.74
2022-06-01 07:00:44 INFO     *** epoch - 11 | train loss - 10.59 | dev f1 - 0.112 | dev loss - 10.67
2022-06-01 07:01:28 INFO     *** epoch - 12 | train loss - 10.47 | dev f1 - 0.148 | dev loss - 10.86
2022-06-01 07:02:13 INFO     *** epoch - 13 | train loss - 10.32 | dev f1 - 0.173 | dev loss - 10.47
2022-06-01 07:02:57 INFO     *** epoch - 14 | train loss - 10.25 | dev f1 - 0.17 | dev loss - 10.57
2022-06-01 07:03:40 INFO     *** epoch - 15 | train loss - 10.2 | dev f1 - 0.191 | dev loss - 10.39
2022-06-01 07:04:25 INFO     *** epoch - 16 | train loss - 10.12 | dev f1 - 0.167 | dev loss - 10.71
2022-06-01 07:05:11 INFO     *** epoch - 17 | train loss - 10.03 | dev f1 - 0.182 | dev loss - 10.4
2022-06-01 07:05:57 INFO     *** epoch - 18 | train loss - 9.94 | dev f1 - 0.265 | dev loss - 10.71
2022-06-01 07:06:41 INFO     *** epoch - 19 | train loss - 9.76 | dev f1 - 0.298 | dev loss - 10.44
2022-06-01 07:07:25 INFO     *** epoch - 20 | train loss - 9.73 | dev f1 - 0.293 | dev loss - 10.15
2022-06-01 07:07:25 INFO     
        yelp ----
2022-06-01 07:07:25 INFO     
        InDomain
        mean -> 0.13050887844240897
        std ->  0.0
        all ->  0.13050887844240897
    
