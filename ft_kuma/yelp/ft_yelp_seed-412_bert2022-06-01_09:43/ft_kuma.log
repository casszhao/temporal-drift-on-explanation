2022-06-01 09:43:28 INFO     Running on cuda : True
2022-06-01 09:43:28 INFO     config  : 
 ----------------------
2022-06-01 09:43:28 INFO     dataset : yelp
2022-06-01 09:43:28 INFO     data_dir : /home/cass/PycharmProjects/ood_time/extract_rationales/datasets/yelp/data/
2022-06-01 09:43:28 INFO     model_dir : /home/cass/PycharmProjects/ood_time/extract_rationales/ft_kuma/yelp/
2022-06-01 09:43:28 INFO     seed : 412
2022-06-01 09:43:28 INFO     evaluate_models : False
2022-06-01 09:43:28 INFO     inherently_faithful : kuma
2022-06-01 09:43:28 INFO     use_tasc : False
2022-06-01 09:43:28 INFO     importance_metric : None
2022-06-01 09:43:28 INFO     rationale_length : 0.2
2022-06-01 09:43:28 INFO     batch_size : 8
2022-06-01 09:43:28 INFO     lr_bert : 1e-05
2022-06-01 09:43:28 INFO     lr_classifier : 0.0001
2022-06-01 09:43:28 INFO     model : bert-base-uncased
2022-06-01 09:43:28 INFO     ood_dataset_1 : yelp_ood1
2022-06-01 09:43:28 INFO     ood_dataset_2 : yelp_ood2
2022-06-01 09:43:28 INFO     epochs : 20
2022-06-01 09:43:28 INFO     model_abbreviation : kuma-bert
2022-06-01 09:43:28 INFO     evaluation_dir : None
2022-06-01 09:43:28 INFO     extracted_rationale_dir : None
2022-06-01 09:43:28 INFO     query : False
2022-06-01 09:43:28 INFO     stage_of_proj : train
2022-06-01 09:43:28 INFO     ood_rat_1 : 0.2
2022-06-01 09:43:28 INFO     ood_rat_2 : 0.2
2022-06-01 09:43:28 INFO     embed_model : glove.840B.300d
2022-06-01 09:43:28 INFO     
 ----------------------
2022-06-01 09:43:30 INFO     2022-06-01_09:43
2022-06-01 09:43:30 INFO     Finetune BERT for: yelp
2022-06-01 09:43:30 INFO     Finetune BERT for: yelp
2022-06-01 09:43:33 INFO     ***************************************
2022-06-01 09:43:33 INFO     Training on seed 412
2022-06-01 09:43:33 INFO     *saving checkpoint every 356 iterations
2022-06-01 09:43:33 INFO     +++++++++++++ epochs:  20
2022-06-01 09:44:14 INFO     *** epoch - 1 | train loss - 12.48 | dev f1 - 0.111 | dev loss - 11.76
2022-06-01 09:44:55 INFO     *** epoch - 2 | train loss - 11.47 | dev f1 - 0.111 | dev loss - 11.47
2022-06-01 09:45:37 INFO     *** epoch - 3 | train loss - 11.47 | dev f1 - 0.111 | dev loss - 11.48
2022-06-01 09:46:18 INFO     *** epoch - 4 | train loss - 11.43 | dev f1 - 0.111 | dev loss - 11.5
2022-06-01 09:46:59 INFO     *** epoch - 5 | train loss - 11.26 | dev f1 - 0.111 | dev loss - 11.27
2022-06-01 09:47:38 INFO     *** epoch - 6 | train loss - 10.87 | dev f1 - 0.112 | dev loss - 11.12
2022-06-01 09:48:18 INFO     *** epoch - 7 | train loss - 10.7 | dev f1 - 0.112 | dev loss - 10.97
2022-06-01 09:49:00 INFO     *** epoch - 8 | train loss - 10.69 | dev f1 - 0.111 | dev loss - 11.13
2022-06-01 09:49:39 INFO     *** epoch - 9 | train loss - 10.59 | dev f1 - 0.133 | dev loss - 10.98
2022-06-01 09:50:19 INFO     *** epoch - 10 | train loss - 10.49 | dev f1 - 0.193 | dev loss - 10.99
2022-06-01 09:50:59 INFO     *** epoch - 11 | train loss - 10.42 | dev f1 - 0.202 | dev loss - 10.81
2022-06-01 09:51:39 INFO     *** epoch - 12 | train loss - 10.38 | dev f1 - 0.203 | dev loss - 10.67
2022-06-01 09:52:19 INFO     *** epoch - 13 | train loss - 10.35 | dev f1 - 0.197 | dev loss - 10.62
2022-06-01 09:52:59 INFO     *** epoch - 14 | train loss - 10.27 | dev f1 - 0.2 | dev loss - 10.54
2022-06-01 09:53:39 INFO     *** epoch - 15 | train loss - 10.22 | dev f1 - 0.197 | dev loss - 10.57
2022-06-01 09:54:21 INFO     *** epoch - 16 | train loss - 10.15 | dev f1 - 0.203 | dev loss - 10.55
2022-06-01 09:55:03 INFO     *** epoch - 17 | train loss - 10.06 | dev f1 - 0.199 | dev loss - 10.51
2022-06-01 09:55:42 INFO     *** epoch - 18 | train loss - 10.0 | dev f1 - 0.197 | dev loss - 10.59
2022-06-01 09:56:21 INFO     *** epoch - 19 | train loss - 9.91 | dev f1 - 0.281 | dev loss - 10.33
2022-06-01 09:57:01 INFO     *** epoch - 20 | train loss - 9.84 | dev f1 - 0.278 | dev loss - 10.34
2022-06-01 09:57:01 INFO     
        yelp ----
2022-06-01 09:57:01 INFO     
        InDomain
        mean -> 0.16464227015024438
        std ->  0.0
        all ->  0.16464227015024438
    
