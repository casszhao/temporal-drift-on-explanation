2022-06-01 07:51:18 INFO     Running on cuda : True
2022-06-01 07:51:18 INFO     config  : 
 ----------------------
2022-06-01 07:51:18 INFO     dataset : yelp
2022-06-01 07:51:18 INFO     data_dir : /home/cass/PycharmProjects/ood_time/extract_rationales/datasets/yelp/data/
2022-06-01 07:51:18 INFO     model_dir : /home/cass/PycharmProjects/ood_time/extract_rationales/ft_kuma/yelp/
2022-06-01 07:51:18 INFO     seed : 412
2022-06-01 07:51:18 INFO     evaluate_models : False
2022-06-01 07:51:18 INFO     inherently_faithful : kuma
2022-06-01 07:51:18 INFO     use_tasc : False
2022-06-01 07:51:18 INFO     importance_metric : None
2022-06-01 07:51:18 INFO     rationale_length : 0.2
2022-06-01 07:51:18 INFO     batch_size : 8
2022-06-01 07:51:18 INFO     lr_bert : 1e-05
2022-06-01 07:51:18 INFO     lr_classifier : 0.0001
2022-06-01 07:51:18 INFO     model : bert-base-uncased
2022-06-01 07:51:18 INFO     ood_dataset_1 : yelp_ood1
2022-06-01 07:51:18 INFO     ood_dataset_2 : yelp_ood2
2022-06-01 07:51:18 INFO     epochs : 20
2022-06-01 07:51:18 INFO     model_abbreviation : kuma-bert
2022-06-01 07:51:18 INFO     evaluation_dir : None
2022-06-01 07:51:18 INFO     extracted_rationale_dir : None
2022-06-01 07:51:18 INFO     query : False
2022-06-01 07:51:18 INFO     stage_of_proj : train
2022-06-01 07:51:18 INFO     ood_rat_1 : 0.2
2022-06-01 07:51:18 INFO     ood_rat_2 : 0.2
2022-06-01 07:51:18 INFO     embed_model : glove.840B.300d
2022-06-01 07:51:18 INFO     
 ----------------------
2022-06-01 07:51:20 INFO     2022-06-01_07:51
2022-06-01 07:51:20 INFO     Finetune BERT for: yelp
2022-06-01 07:51:20 INFO     Finetune BERT for: yelp
2022-06-01 07:51:23 INFO     ***************************************
2022-06-01 07:51:23 INFO     Training on seed 412
2022-06-01 07:51:23 INFO     *saving checkpoint every 356 iterations
2022-06-01 07:51:23 INFO     +++++++++++++ epochs:  20
2022-06-01 07:52:06 INFO     *** epoch - 1 | train loss - 12.19 | dev f1 - 0.111 | dev loss - 11.51
2022-06-01 07:52:50 INFO     *** epoch - 2 | train loss - 11.45 | dev f1 - 0.112 | dev loss - 11.41
2022-06-01 07:53:34 INFO     *** epoch - 3 | train loss - 11.36 | dev f1 - 0.112 | dev loss - 11.33
2022-06-01 07:54:17 INFO     *** epoch - 4 | train loss - 11.24 | dev f1 - 0.114 | dev loss - 11.17
2022-06-01 07:55:01 INFO     *** epoch - 5 | train loss - 10.97 | dev f1 - 0.138 | dev loss - 11.35
2022-06-01 07:55:45 INFO     *** epoch - 6 | train loss - 10.99 | dev f1 - 0.154 | dev loss - 11.57
2022-06-01 07:56:29 INFO     *** epoch - 7 | train loss - 11.34 | dev f1 - 0.168 | dev loss - 12.4
2022-06-01 07:57:08 INFO     *** epoch - 8 | train loss - 12.19 | dev f1 - 0.228 | dev loss - 13.42
2022-06-01 07:57:47 INFO     *** epoch - 9 | train loss - 14.31 | dev f1 - 0.252 | dev loss - 16.46
2022-06-01 07:58:26 INFO     *** epoch - 10 | train loss - 19.0 | dev f1 - 0.273 | dev loss - 23.07
2022-06-01 07:59:06 INFO     *** epoch - 11 | train loss - 29.37 | dev f1 - 0.283 | dev loss - 37.74
2022-06-01 07:59:45 INFO     *** epoch - 12 | train loss - 52.11 | dev f1 - 0.292 | dev loss - 69.22
2022-06-01 08:00:24 INFO     *** epoch - 13 | train loss - 101.29 | dev f1 - 0.299 | dev loss - 137.26
2022-06-01 08:01:03 INFO     *** epoch - 14 | train loss - 162.1 | dev f1 - 0.111 | dev loss - -39.0
2022-06-01 08:01:42 INFO     *** epoch - 15 | train loss - -42.26 | dev f1 - 0.111 | dev loss - -38.28
2022-06-01 08:02:21 INFO     *** epoch - 16 | train loss - -33.43 | dev f1 - 0.111 | dev loss - -29.64
2022-06-01 08:03:00 INFO     *** epoch - 17 | train loss - -25.62 | dev f1 - 0.111 | dev loss - -22.48
2022-06-01 08:03:39 INFO     *** epoch - 18 | train loss - -19.16 | dev f1 - 0.111 | dev loss - -16.56
2022-06-01 08:04:18 INFO     *** epoch - 19 | train loss - -13.81 | dev f1 - 0.111 | dev loss - -11.67
2022-06-01 08:04:57 INFO     *** epoch - 20 | train loss - -9.4 | dev f1 - 0.111 | dev loss - -7.63
2022-06-01 08:04:57 INFO     
        yelp ----
2022-06-01 08:04:57 INFO     
        InDomain
        mean -> 0.0
        std ->  0.0
        all ->  0.0
    
